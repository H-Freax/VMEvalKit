# VMEvalKit Quick Reference Card

## ğŸ¯ The One Rule
**ALWAYS use InferenceRunner - NEVER use API clients directly!**

## ğŸ Python Usage

```python
from vmevalkit import InferenceRunner

# Single video generation
runner = InferenceRunner()
result = runner.run(
    model_name="luma-dream-machine",  # â† Just change this!
    image_path="maze.png",
    text_prompt="Solve this maze"
)

# From dataset task
result = runner.run_from_task(
    model_name="luma-dream-machine",
    task_data=task
)
```

## ğŸ’» CLI Usage

```bash
# Single inference
vmevalkit inference luma-dream-machine \
    --image maze.png \
    --prompt "Solve this maze"

# Batch on dataset
vmevalkit batch luma-dream-machine \
    --dataset data/maze_tasks.json \
    --max-tasks 5
```

## ğŸš« Never Do This

```python
# âŒ WRONG
from vmevalkit.api_clients import LumaClient

# âŒ WRONG  
from vmevalkit.models.luma import LumaModel

# âŒ WRONG
model = ModelRegistry.load_model(...)
video = model.generate(...)  # No logging!
```

## âœ… Always Do This

```python
# âœ… CORRECT
from vmevalkit import InferenceRunner
runner = InferenceRunner()
result = runner.run(...)
```

## ğŸ“ Output Location
- Videos: `outputs/luma_<id>.mp4`
- Logs: `outputs/inference_runs.json`
- Batch results: `outputs/batch_results/`

## ğŸ”„ Switch Models
Just change the model name:
- `"luma-dream-machine"`
- `"google-veo-001"`
- `"runway-gen3"`

---
*See TEAM_INSTRUCTIONS.md for full details*
