
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Installing: hunyuan-video-i2v
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Virtual Environment
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”§ Removing existing environment: hunyuan-video-i2v
   âœ… Old environment removed
ğŸ”§ Creating virtual environment: hunyuan-video-i2v
   âœ… Virtual environment created: hunyuan-video-i2v

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dependencies
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Checkpoints
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â­ï¸  HunyuanVideo-I2V weights already present at /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
ğŸ“¥ Removing incomplete text encoder...
ğŸ“¥ Downloading HunyuanVideo-I2V text encoder (xtuner/llava-llama-3-8b-v1_1-transformers) to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v...
/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.
  warnings.warn(
/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]Downloading 'model-00002-of-00004.safetensors' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/model-00002-of-00004.safetensors.268d2a5b0427bf992dd67e79fd1db200b6f95be61867bfe9345d370be2e6c68a.incomplete'
Downloading 'generation_config.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/generation_config.json.d7cd6a7c07c68df35cbd28ff2dafdc0a44d123ec.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/generation_config.json
Downloading 'config.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/config.json.d5c45ce4de7e5e4a7ceb0603c8730152f412f35a.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/config.json
Downloading '.gitattributes' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/.gitattributes.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'
Downloading 'model-00001-of-00004.safetensors' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/model-00001-of-00004.safetensors.9bb04e272165e426273ce0524e139e2e0a67df322b337a21dc3cad757839bbd9.incomplete'
Downloading 'model.safetensors.index.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/model.safetensors.index.json.54584d21690023aab789069877f431cc4fc8f741.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.gitattributes
Downloading 'preprocessor_config.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/preprocessor_config.json.cf5bb0ca8379e4a63885f0c9ffbaabd10370efdd.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/model.safetensors.index.json
Fetching 13 files:   8%|â–Š         | 1/13 [00:00<00:04,  2.56it/s]Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/preprocessor_config.json
Downloading 'README.md' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/README.md.6660276bf4424ff53a44099ccae5c4018c2b153b.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/README.md
Downloading 'tokenizer.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/tokenizer.json.99f23954b4bade407d4f3a18892f21f80b412d68.incomplete'
Downloading 'tokenizer_config.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/tokenizer_config.json.ee0b862ccbead8e22e0e69d9c6b7d11a5a1eef98.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/tokenizer_config.json
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/tokenizer.json
Downloading 'model-00004-of-00004.safetensors' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/model-00004-of-00004.safetensors.8549ed634cc7b55fe3e1855855f6dfb369f496fcd7ddc5c21a5ed994e5a0dbe9.incomplete'
Downloading 'special_tokens_map.json' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/special_tokens_map.json.b538bedbe8b14719dd9c222a993a58568ea7ecab.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/special_tokens_map.json
Downloading 'model-00003-of-00004.safetensors' to '/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/.cache/huggingface/download/model-00003-of-00004.safetensors.3f8e9275cbb4ffa5607ce95502532aae71377284b251efe4c71f76883318f9ba.incomplete'
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/model-00004-of-00004.safetensors
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/model-00001-of-00004.safetensors
Fetching 13 files:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 5/13 [00:29<00:49,  6.15s/it]Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/model-00003-of-00004.safetensors
Download complete. Moving file to /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v/model-00002-of-00004.safetensors
Fetching 13 files:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:43<00:57,  8.16s/it]Fetching 13 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:43<00:00,  3.37s/it]
/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
   âœ… Text encoder ready at /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/text_encoder_i2v
   âœ… hunyuan-video-i2v setup complete
   âœ… hunyuan-video-i2v installed successfully

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Validation Phase
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Validating: hunyuan-video-i2v
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ”§ Validating hunyuan-video-i2v... (timeout: 10800s)

ğŸ” Discovering human-approved tasks from folder structure...
ğŸ” Discovering tasks by scanning actual files: data/questions
   ğŸ“ Scanning tests_task/
      âœ… Found 2 approved tasks in tests

ğŸ“Š Discovery Summary:
   Total approved tasks: 2
   Tests: 2 tasks
   ğŸ¯ Running specific task IDs: tests_0001, tests_0002

ğŸ¯ Selected 1 model(s): hunyuan-video-i2v

ğŸ” Verifying 1 model(s) for testing...
   âœ… hunyuan-video-i2v: HunyuanVideo
ğŸš€ VMEVAL KIT EXPERIMENT - CLEAN EXECUTION

ğŸ“Š Experiment Configuration:
   Models to run: 1 - hunyuan-video-i2v
   Domains: 1
   ğŸ”„ Execution Mode: SEQUENTIAL

ğŸ“ˆ Task Distribution:
   Tests: 2 approved tasks
   Total approved tasks: 2
   Total generations: 2

ğŸ“ Output directory: data/outputs/pilot_experiment
   Skip existing: True

ğŸ“ Output directory structure ready at: data/outputs/pilot_experiment
   Each inference will create a self-contained folder with:
   - video/: Generated video file
   - question/: Input images and prompt
   - metadata.json: Complete inference metadata
ğŸ“ Created per-model folders under: data/outputs/pilot_experiment and mirrored question tasks
ğŸ“‹ Total inference jobs to run: 2
ğŸš€ Starting sequential execution...

   Processing order: Model by model, task by task

ğŸ¤– Processing Model: HunyuanVideo (hunyuan-video-i2v)

  ğŸ“š Domain: Tests
    [1/2] Processing: tests_0001

  ğŸ¬ Generating: tests_0001 with hunyuan-video-i2v
     Image: /lambda/nfs/Hokin/VMEvalKit/data/questions/tests_task/tests_0001/first_frame.png
     Prompt: Remove all cone objects from the scene. Do not do anything to other objects....
ğŸ“¦ Loaded model: hunyuan-video-i2v (will be reused for all tasks)
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

âœ… Inference complete! Output saved to: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0001/hunyuan-video-i2v_tests_0001_20251228_015703
   - Video: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0001/hunyuan-video-i2v_tests_0001_20251228_015703/video/
   - Question data: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0001/hunyuan-video-i2v_tests_0001_20251228_015703/question/
   - Metadata: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0001/hunyuan-video-i2v_tests_0001_20251228_015703/metadata.json
     âŒ Failed: /home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
2025-12-28 01:57:18.620 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2025-12-28 01:57:18.620 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2025-12-28 01:57:19.042 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2025-12-28 01:57:47.437 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-i2v-720p/vae
2025-12-28 01:57:49.870 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-12-28 01:57:49.980 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: ./ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:17,  5.83s/it]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:11<00:11,  5.70s/it]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:17<00:05,  5.68s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.17s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.74s/it]
2025-12-28 01:58:12.281 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2025-12-28 01:58:14.777 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: ./ckpts/text_encoder_i2v
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
2025-12-28 01:58:15.195 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: ./ckpts/text_encoder_2
Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './ckpts/text_encoder_2'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 25, in main
    hunyuan_video_sampler = HunyuanVideoSampler.from_pretrained(models_root_path, args=args)
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 331, in from_pretrained
    text_encoder_2 = TextEncoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 201, in __init__
    self.model, self.model_path = load_text_encoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 40, in load_text_encoder
    text_encoder = CLIPTextModel.from_pretrained(text_encoder_path)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3506, in from_pretrained
    resolved_config_file = cached_file(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: './ckpts/text_encoder_2'. Please provide either the path to a local folder or the repo_id of a model on the Hub.

      âŒ Failed: /home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
2025-12-28 01:57:18.620 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2025-12-28 01:57:18.620 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2025-12-28 01:57:19.042 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2025-12-28 01:57:47.437 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-i2v-720p/vae
2025-12-28 01:57:49.870 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-12-28 01:57:49.980 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: ./ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:17,  5.83s/it]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:11<00:11,  5.70s/it]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:17<00:05,  5.68s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.17s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.74s/it]
2025-12-28 01:58:12.281 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2025-12-28 01:58:14.777 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: ./ckpts/text_encoder_i2v
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
2025-12-28 01:58:15.195 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: ./ckpts/text_encoder_2
Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './ckpts/text_encoder_2'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 25, in main
    hunyuan_video_sampler = HunyuanVideoSampler.from_pretrained(models_root_path, args=args)
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 331, in from_pretrained
    text_encoder_2 = TextEncoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 201, in __init__
    self.model, self.model_path = load_text_encoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 40, in load_text_encoder
    text_encoder = CLIPTextModel.from_pretrained(text_encoder_path)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3506, in from_pretrained
    resolved_config_file = cached_file(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: './ckpts/text_encoder_2'. Please provide either the path to a local folder or the repo_id of a model on the Hub.

    [2/2] Processing: tests_0002

  ğŸ¬ Generating: tests_0002 with hunyuan-video-i2v
     Image: /lambda/nfs/Hokin/VMEvalKit/data/questions/tests_task/tests_0002/first_frame.png
     Prompt: The image shows a horizontally flipped clock. After 2 hours passes on the origin...
Warning: HunyuanVideo requires 60-80GB GPU memory for 720p generation

âœ… Inference complete! Output saved to: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0002/hunyuan-video-i2v_tests_0002_20251228_015817
   - Video: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0002/hunyuan-video-i2v_tests_0002_20251228_015817/video/
   - Question data: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0002/hunyuan-video-i2v_tests_0002_20251228_015817/question/
   - Metadata: data/outputs/pilot_experiment/hunyuan-video-i2v/tests_task/tests_0002/hunyuan-video-i2v_tests_0002_20251228_015817/metadata.json
     âŒ Failed: /home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
2025-12-28 01:58:28.509 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2025-12-28 01:58:28.510 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2025-12-28 01:58:28.771 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2025-12-28 01:58:55.666 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-i2v-720p/vae
2025-12-28 01:58:58.030 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-12-28 01:58:58.140 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: ./ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/it]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:06<00:06,  3.17s/it]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:07<00:02,  2.43s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  1.71s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.15s/it]
2025-12-28 01:59:09.875 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2025-12-28 01:59:12.452 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: ./ckpts/text_encoder_i2v
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
2025-12-28 01:59:12.785 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: ./ckpts/text_encoder_2
Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './ckpts/text_encoder_2'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 25, in main
    hunyuan_video_sampler = HunyuanVideoSampler.from_pretrained(models_root_path, args=args)
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 331, in from_pretrained
    text_encoder_2 = TextEncoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 201, in __init__
    self.model, self.model_path = load_text_encoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 40, in load_text_encoder
    text_encoder = CLIPTextModel.from_pretrained(text_encoder_path)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3506, in from_pretrained
    resolved_config_file = cached_file(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: './ckpts/text_encoder_2'. Please provide either the path to a local folder or the repo_id of a model on the Hub.

      âŒ Failed: /home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/torch/utils/cpp_extension.py:28: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging  # type: ignore[attr-defined]
2025-12-28 01:58:28.509 | INFO     | hyvideo.inference:from_pretrained:220 - Got text-to-video model root path: /home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/ckpts/hunyuan-video-i2v-720p
2025-12-28 01:58:28.510 | INFO     | hyvideo.inference:from_pretrained:258 - Building model...
2025-12-28 01:58:28.771 | INFO     | hyvideo.inference:load_state_dict:494 - Loading torch model ckpts/hunyuan-video-i2v-720p/transformers/mp_rank_00_model_states.pt...
2025-12-28 01:58:55.666 | INFO     | hyvideo.vae:load_vae:29 - Loading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-i2v-720p/vae
2025-12-28 01:58:58.030 | INFO     | hyvideo.vae:load_vae:55 - VAE to dtype: torch.float16
2025-12-28 01:58:58.140 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (llm-i2v) from: ./ckpts/text_encoder_i2v

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/it]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:06<00:06,  3.17s/it]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:07<00:02,  2.43s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  1.71s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.15s/it]
2025-12-28 01:59:09.875 | INFO     | hyvideo.text_encoder:load_text_encoder:61 - Text encoder to dtype: torch.float16
2025-12-28 01:59:12.452 | INFO     | hyvideo.text_encoder:load_tokenizer:75 - Loading tokenizer (llm-i2v) from: ./ckpts/text_encoder_i2v
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.
2025-12-28 01:59:12.785 | INFO     | hyvideo.text_encoder:load_text_encoder:35 - Loading text encoder model (clipL) from: ./ckpts/text_encoder_2
Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 403, in cached_file
    resolved_file = hf_hub_download(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 106, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 154, in validate_repo_id
    raise HFValidationError(
huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './ckpts/text_encoder_2'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 65, in <module>
    main()
  File "/home/ubuntu/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/sample_image2video.py", line 25, in main
    hunyuan_video_sampler = HunyuanVideoSampler.from_pretrained(models_root_path, args=args)
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/inference.py", line 331, in from_pretrained
    text_encoder_2 = TextEncoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 201, in __init__
    self.model, self.model_path = load_text_encoder(
  File "/lambda/nfs/Hokin/VMEvalKit/submodules/HunyuanVideo-I2V/hyvideo/text_encoder/__init__.py", line 40, in load_text_encoder
    text_encoder = CLIPTextModel.from_pretrained(text_encoder_path)
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3506, in from_pretrained
    resolved_config_file = cached_file(
  File "/home/ubuntu/Hokin/VMEvalKit/envs/hunyuan-video-i2v/lib/python3.10/site-packages/transformers/utils/hub.py", line 469, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: './ckpts/text_encoder_2'. Please provide either the path to a local folder or the repo_id of a model on the Hub.


  ğŸ“Š Model HunyuanVideo Summary: 0 completed, 2 failed, 0 skipped in 0h 2m 10s

â±ï¸  Sequential execution completed in 0h 2m 10s
ğŸ‰ VIDEO GENERATION COMPLETE!

ğŸ“Š Final Statistics:
   Models tested: 1
   Tasks per model: 2
   Total possible generations: 2
   Total attempted: 2
   Completed: 0 (0.0%)
   Failed: 2 (100.0%)
   Skipped: 0 (0.0%)
   â±ï¸ Duration: 0h 2m 10s

ğŸ¯ Results by Domain:
   Tests: âœ… 0 completed | âŒ 2 failed | â­ï¸  0 skipped

ğŸ¤– Results by Model:
   hunyuan-video-i2v: âœ… 0 | âŒ 2 | â­ï¸  0

ğŸ“ All outputs saved to: data/outputs/pilot_experiment
   âŒ hunyuan-video-i2v: FAILED - see output above

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Validation Summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


   âŒ Failed (1):
      âœ— hunyuan-video-i2v

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Installation Summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

   âœ… Installed (1):
      âœ“ hunyuan-video-i2v

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… All installations completed successfully
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

